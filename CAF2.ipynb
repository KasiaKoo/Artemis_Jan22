{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the Saphire Iris Rotation Run\n",
    "\n",
    "Before you go on with your analysis maybe download the 014 Andor scan and run this file to see if it works properly. Then duplicate that file and copy the cells you want to recreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## necessary import statements\n",
    "from HARP.scan_anal import Scan\n",
    "from HARP.iris_functions import Iris\n",
    "from HARP.image_processing import Image\n",
    "import os\n",
    "from scipy.optimize import curve_fit\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from functions import Andor_calib\n",
    "from functions import Adams_wedge_thickness\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup your scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your iris calibration that was used on that day (check if the hour is correct)\n",
    "power = np.array([4, 160, 450, 370, 570, 630, 670, 720, 720, 31, 35, 63, 110, 150, 230, 280, 330,350])*1e-3 #list is in mW as that is what we wrote down but the multiplication is to change it to W\n",
    "iris_pos= np.array([-45, -40, -35, -30, -25, -20, -15, -10,-44,-43, -42, -41, -40, -39, -38,-37,-36]) #make sure you have same number of iris positions and powers\n",
    "iris = Iris()\n",
    "iris.specify_calib(iris_positions=iris_pos, powers=power)\n",
    "iris.specify_params(w0_init=100e-6, f=0.75, wl=1800e-9, M2=1, reprate=1000,pulse_duration=15e-15) #specify your params!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify where the folder in which the files are:\n",
    "data_folder = os.path.join('../../../Data') #first argument where you store your data and second is specific folder\n",
    "#h5files = [i for i in os.listdir(data_folder) if i != 'Camera.h5'] # I am only taking one of the cycles for now\n",
    "h5file = 'ImgData-000-20220202-233423.h5'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open the Scan class\n",
    "caf2 = Scan()\n",
    "caf2.set_folder(data_folder)\n",
    "# fill out which are available from \n",
    "caf2.set_params(iris=None, wedge=1060, rotation=None, MCPPos=90000) # here fill out the variables that you are not scanning through. This scan is Rotation and iris so I fill out the other MCPPos and Wedge\n",
    "caf2.set_verlim(125, 275) #this is the vertical cropping you want to do\n",
    "caf2.set_eVlim((7,23)) #this is the energy limits you want to look at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Add pictures to the scan\n",
    "\n",
    "# #To add individual file uncomment the following:\n",
    "caf2.populate_scan_h5(h5file, function=Andor_calib)\n",
    "\n",
    "# #To add all files or at least multiples uncomment:\n",
    "#for f in h5files:\n",
    "#    try:\n",
    "#        saph.populate_scan_h5(f, function=Andor_calib)\n",
    "#    except:\n",
    "#        print('Failed to add {}'.format(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes file fail to add so we need the try expect to avoid it. Good practise is to go and investigate why - the 003 file in Saph was for example 0 bites so I assume the file got corrupted. Also might be easier to do main analysis on only one cycle first and only then add more files and rerun the code - for example it is possible something change in the lab or something.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I use this to plot quickly the average to so I can see how to crop and eV limits - when you know what you want just rerun, staritng from Scan() cell, with new limits\n",
    "fig, ax = plt.subplots(2)\n",
    "im, ax[0], ax2 = caf2.plot_average(ax[0])\n",
    "ax[0].set_title('Average Trace')\n",
    "ax[0].xaxis.tick_top()\n",
    "ax[0].set_xlabel('Energy [eV]', va = 'top')\n",
    "ax[0].set_ylabel('Divergence [a.u.]')\n",
    "ax[0].set_xlim(9,23)\n",
    "ax[0].set_ylim(125,275)\n",
    "#im, ax[1] = caf2.plot_scan_mean(ax[1], 'iris')\n",
    "#ax[1].set_xlabel('Iris')\n",
    "#ax[1].set_ylabel('Energy eV')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with background\n",
    "So dealing with background is not trivial and I have to work on it a bit more. \n",
    "For same background on all plots you can use 3 different ways. \n",
    "a) add_background_from_scan(self, closed_iris_position = -45)\n",
    "\n",
    "This points to the position od fully closed iris and sets it as the background array for all your pictures\n",
    "\n",
    "b) add_background(self, bg_array)\n",
    "\n",
    "Here you can upload another numpy array e.g. if you saved a file before you started scan\n",
    "\n",
    "c) Do nothing and expect it to find itself\n",
    "\n",
    "if you use a or b just then run \n",
    "scan.substract_bg() \n",
    "\n",
    "if you chose c) \n",
    "you need to specify which part of the scan you want to take as mean - e.g. if you want to take the 0,10 corner and a square of 10 by 20 run: \n",
    "scan.substract_bg(byitself=True, bg_lim = [0,10,10,20])\n",
    "\n",
    "*Other things to add is getting rid of those tiny dots*\n",
    "\n",
    "*Also work on scatter?*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding background by itself:\n",
    "\n",
    "#caf2.substract_bg(byitself=True, bg_lim=[-10,-10,10,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the different column variables if you want.\n",
    "\n",
    "# Adding intensity variable based on iris position \n",
    "caf2.add_calibration_stage('intensity', iris.get_intensity_TWcm2, 'iris')\n",
    "\n",
    "#Adding glass thickness based on wedge position\n",
    "caf2.add_calibration_stage('thickness', Adams_wedge_thickness, 'wedge')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is just a pandas data frama that contains the Trace object - which you can access the raw data as trace.data but also for each trace it has the variables for which this trace was taken. Data Frame gives us an advantage as you can easily sort and remove specific values with it before you go into analysis. \n",
    "\n",
    "Things like adding calibrations or substracting background should only be done once! so if you need ot change it - just the whole scan making section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with the Scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the easiest way to think about this class it containes a pandas data frame as shown above and some basic functions to show the plots. Here I show easy ways to play with the data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x, y, Z = caf2.return_scan_data('iris')\n",
    "fig, ax = plt.subplots(figsize = (20,10))\n",
    "l1, l2, l3 = (400,1200,700)\n",
    "cma = ax.contourf(y,x,Z, levels=np.linspace(0,l1,20), cmap='pink')\n",
    "cba = plt.colorbar(cma, ax=ax)\n",
    "cmb = ax.contourf(y,x,Z, levels=np.linspace(l1,l2,100), cmap='nipy_spectral_r')\n",
    "cbb = plt.colorbar(cmb, ax=ax)\n",
    "cmc = ax.contourf(y,x,Z, levels=np.linspace(l2,max(Z.flatten()),20), cmap='cubehelix')\n",
    "cbc = plt.colorbar(cmc, ax=ax)\n",
    "plt.xlim(9,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape, y.shape, Z.shape)\n",
    "l1, l2 = Z.shape\n",
    "new_array = np.append(x.reshape((21,1)), Z).reshape((l1,l2+1))\n",
    "print(new_array.shape)\n",
    "new_array = np.append(np.append([np.NaN], y.reshape((1, 1602))).reshape((1,l2+1)), new_array, axis =0).reshape(l1+1, l2+1)\n",
    "new_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_array\n",
    "np.savez('test.npz', x, y, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, Z = saph.return_scan_data('rotation')\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "r,theta = np.meshgrid(y,np.radians(x))\n",
    "l4 =1100\n",
    "pa = ax.contourf(theta, r, Z, levels=np.linspace(100,l4,50), cmap='nipy_spectral_r')\n",
    "pb = ax.contourf(theta, r, Z, levels=np.linspace(l4,max(Z.flatten()),20), cmap='cubehelix')\n",
    "ax.set_thetalim(np.radians(min(x)), np.radians(max(x)))\n",
    "ax.set_rlim(10,23)\n",
    "cba = plt.colorbar(pa, ax=ax)\n",
    "cbb = plt.colorbar(pb, ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is the easiest way to do stuff. What is does is it groups the data frame by the specific stage you specify and then it returns the mean of each group. Then it finds the lineout.  But as we have it all in dataframe it is easy to pick specific groups for example at the bottom I repeat the roation plots for different internsities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image()\n",
    "irises= np.unique(saph.scan_data.iris)\n",
    "inten = [iris.get_intensity_TWcm2(i) for i in irises]\n",
    "fig, ax = plt.subplots(2,2,subplot_kw={'projection': 'polar'}, figsize=(20,20))\n",
    "ax = ax.flatten()\n",
    "for i in range(len(irises)):\n",
    "    df = saph.scan_data[saph.scan_data['iris']==irises[i]]\n",
    "    x,y,Z = saph.return_scan_data('rotation', df = df)\n",
    "    img.load_image(Z)\n",
    "    img.remove_dead_pix()\n",
    "    img.improve_contrast(0.8)\n",
    "    r,theta = np.meshgrid(y,np.radians(x))\n",
    "    l5 = max(Z.flatten())\n",
    "    pa = ax[i].contourf(theta, r, Z, levels=np.linspace(0,l5/4,50), cmap='nipy_spectral_r')\n",
    "    pb = ax[i].contourf(theta, r, Z, levels=np.linspace(l5/4,l5,20), cmap='cubehelix')\n",
    "    ax[i].set_thetalim(np.radians(min(x)), np.radians(max(x)))\n",
    "    ax[i].set_title('Intensity {} TW/cm2'.format(np.round(inten[i],2)))\n",
    "    cba = plt.colorbar(pa, ax=ax[i])\n",
    "    cbb = plt.colorbar(pb, ax=ax[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96267f45aa239f7579941d6828f831f322b79bfb76f99871cc5e25b5a2000bd9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
